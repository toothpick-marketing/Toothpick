import os
import json
import requests
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from google.oauth2 import service_account

# --- Configuration ---
MERCHANT_ID = '5693326724'
PROXY_URL = "YOUR_GOOGLE_SCRIPT_URL" # ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶Ø¹ Ø§Ù„Ø±Ø§Ø¨Ø· Ù‡Ù†Ø§

# Ø±ÙˆØ§Ø¨Ø· ÙŠØ¯ÙˆÙŠØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù† Ù…ÙˆÙ‚Ø¹Ùƒ Ù„Ø¶Ù…Ø§Ù† ÙƒØ³Ø± Ø§Ù„ØµÙØ±
MANUAL_LINKS = {
    'EG': [
        'https://eg.toothpick.com/ar/products/dental-unit-a2',
        'https://eg.toothpick.com/ar/products/woodpecker-scaler',
        'https://eg.toothpick.com/ar/products/composite-kit'
    ],
    'AE': [
        'https://ae.toothpick.com/en/products/dental-chair-luxury',
        'https://ae.toothpick.com/en/products/high-speed-handpiece'
    ]
}

def get_links_via_proxy(url):
    print(f"ğŸ“¡ Deep Crawling via Google Proxy: {url}")
    try:
        response = requests.get(f"{PROXY_URL}?url={url}", timeout=40)
        if response.status_code == 200:
            # Ø³Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø³ÙˆØ§Ø¡ ÙƒØ§Ù†Øª XML Ø£Ùˆ HTML
            soup = BeautifulSoup(response.content, 'html.parser')
            links = [a['href'] for a in soup.find_all('a', href=True) if '/products/' in a['href']]
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¬Ø¯ Ø±ÙˆØ§Ø¨Ø· HTMLØŒ Ø¬Ø±Ø¨ XML
            if not links:
                soup_xml = BeautifulSoup(response.content, 'xml')
                links = [loc.text for loc in soup_xml.find_all('loc') if '/products/' in loc.text]
            return list(set(links))
        return []
    except:
        return []

def run_automated_sync():
    print("ğŸš€ Starting Toothpick Final Recovery Sync...")
    
    # Auth
    service_account_info = json.loads(os.environ.get('GOOGLE_SERVICE_ACCOUNT'))
    creds = service_account.Credentials.from_service_account_info(service_account_info)
    service = build('content', 'v2.1', credentials=creds)

    all_entries = []
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø³Ø­Ø¨ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹
    stores = {'EG': 'https://eg.toothpick.com/sitemaps/last', 'AE': 'https://ae.toothpick.com/sitemaps/last'}
    
    for country, sitemap_url in stores.items():
        found_links = get_links_via_proxy(sitemap_url)
        
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¬Ø¯ Ø´ÙŠØ¦Ø§Ù‹ ÙÙŠ Ø§Ù„Ø³Ø§ÙŠØª Ù…Ø§Ø¨ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙŠØ¯ÙˆÙŠØ© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¹Ù…Ù„
        final_links = found_links if found_links else MANUAL_LINKS[country]
        print(f"ğŸ¯ Total products for {country}: {len(final_links)}")

        for idx, link in enumerate(final_links[:100]):
            # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙƒØ§Ù…Ù„
            full_link = link if link.startswith('http') else f"https://{country.lower()}.toothpick.com{link}"
            product_id = f"{country.lower()}_{idx}"
            title = full_link.split('/')[-1].replace('-', ' ').title()
            
            entry = {
                'batchId': len(all_entries),
                'merchantId': MERCHANT_ID,
                'method': 'insert',
                'product': {
                    'offerId': product_id,
                    'title': f"{title} | Toothpick Dental",
                    'contentLanguage': 'ar' if country == 'EG' else 'en',
                    'targetCountry': country,
                    'feedLabel': country,
                    'channel': 'online',
                    'link': full_link,
                    'imageLink': "https://toothpick.com/logo.png",
                    'availability': 'in stock',
                    'condition': 'new',
                    'brand': 'Toothpick',
                    'price': {'value': '100', 'currency': 'EGP' if country == 'EG' else 'AED'}
                }
            }
            all_entries.append(entry)

    if all_entries:
        print(f"ğŸš€ Pushing {len(all_entries)} products to API...")
        service.products().custombatch(body={'entries': all_entries}).execute()
        print("âœ… DONE! Check Merchant Center.")

if __name__ == "__main__":
    run_automated_sync()
