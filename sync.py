import os
import json
import requests
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from google.oauth2 import service_account

# --- Configuration ---
MERCHANT_ID = '5693326724'
PRODUCT_SITEMAPS = {
    'EG': [
        'https://eg.toothpick.com/sitemap-products-1.xml',
        'https://eg.toothpick.com/sitemap-products-2.xml'
    ],
    'SA': [
        'https://sa.toothpick.com/sitemap-products-1.xml',
        'https://sa.toothpick.com/sitemap-products-2.xml'
    ]
}

# ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ Headers Ù„Ù…Ø­Ø§ÙƒØ§Ø© Googlebot Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive',
    'Upgrade-In-Requests': '1'
}

def get_links_from_xml(url):
    print(f"ğŸ”— Attempting to access: {url}")
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… session Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„
        session = requests.Session()
        response = session.get(url, headers=HEADERS, timeout=30)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'xml')
            links = [loc.text for loc in soup.find_all('loc')]
            return links
        else:
            print(f"âŒ Access Denied: Status {response.status_code} on {url}")
            return []
    except Exception as e:
        print(f"âš ï¸ Connection Error: {e}")
        return []

def run_automated_sync():
    print("ğŸš€ Starting Toothpick Official Sync (Googlebot Mode)...")
    
    # Auth
    service_account_info = json.loads(os.environ.get('GOOGLE_SERVICE_ACCOUNT'))
    creds = service_account.Credentials.from_service_account_info(service_account_info)
    service = build('content', 'v2.1', credentials=creds)

    all_entries = []
    
    for country, sitemaps in PRODUCT_SITEMAPS.items():
        country_links = []
        for s_url in sitemaps:
            links = get_links_from_xml(s_url)
            country_links += links
        
        print(f"ğŸ¯ Products found for {country}: {len(country_links)}")

        # Ø¥Ø°Ø§ Ù†Ø¬Ø­ Ø§Ù„Ø³Ø­Ø¨ØŒ Ù†Ø±ÙØ¹ Ø£ÙˆÙ„ 150 Ù…Ù†ØªØ¬
        if country_links:
            for idx, link in enumerate(country_links[:150]):
                product_id = f"{country.lower()}_{idx}"
                brand = link.split('/')[-1].split('-')[0].capitalize()
                
                entry = {
                    'batchId': len(all_entries),
                    'merchantId': MERCHANT_ID,
                    'method': 'insert',
                    'product': {
                        'offerId': product_id,
                        'title': f"{brand} - Professional Dental Supply",
                        'contentLanguage': 'ar',
                        'targetCountry': country,
                        'feedLabel': country,
                        'channel': 'online',
                        'link': link,
                        'imageLink': "https://toothpick.com/logo.png",
                        'availability': 'in stock',
                        'condition': 'new',
                        'brand': brand,
                        'price': {'value': '100', 'currency': 'EGP' if country == 'EG' else 'SAR'}
                    }
                }
                all_entries.append(entry)

    if all_entries:
        print(f"ğŸš€ Pushing {len(all_entries)} products to API...")
        service.products().custombatch(body={'entries': all_entries}).execute()
        print("âœ… Success! Sync complete.")
    else:
        print("âŒ Still getting 403. Please ask the dev to allow 'Googlebot' User-Agent in Cloudflare.")

if __name__ == "__main__":
    run_automated_sync()
